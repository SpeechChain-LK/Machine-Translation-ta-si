{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install transformers torch datasets sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -U \"transformers[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -U \"accelerate>=0.26.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install sacrebleu evaluate rouge_score bert_score tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Model Loading (Updated to mT5)\n",
    "# ----------------------\n",
    "!pip install evaluate\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "# Load mT5-small model and tokenizer\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# mT5 uses different language codes than T5\n",
    "tokenizer.src_lang = \"tam_IN\"  # Tamil\n",
    "tokenizer.tgt_lang = \"sin_LK\"  # Sinhala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Data Loading (Unchanged)\n",
    "# ----------------------\n",
    "# !pip install -U datasets\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": \"/kaggle/input/mt5-data/train.tsv\",\n",
    "        # \"validation\": \"/kaggle/input/mt5-data/val.tsv\",\n",
    "        \"test\": \"/kaggle/input/mt5-data/test.tsv\"\n",
    "    },\n",
    "    delimiter=\"\\t\",\n",
    "    column_names=[\"source\", \"target\"]\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "print(\"Train Sample:\", dataset[\"train\"][1])\n",
    "print(\"Validation Sample:\", dataset[\"validation\"][1])\n",
    "print(\"Test Sample:\", dataset[\"test\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Preprocessing (Updated for mT5)\n",
    "# ----------------------\n",
    "def preprocess_function(examples):\n",
    "    # mT5 doesn't need forced prefix like T5, but we'll keep it for consistency\n",
    "    inputs = [\"translate Tamil to Sinhala: \" + ex for ex in examples[\"source\"]]\n",
    "    targets = [ex for ex in examples[\"target\"]]\n",
    "\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Updated tokenizer call (no more as_target_tokenizer)\n",
    "    labels = tokenizer(\n",
    "        text_target=targets,  # New recommended way\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "bleu = load(\"sacrebleu\")\n",
    "rouge = load(\"rouge\")\n",
    "chrf = load(\"chrf\")\n",
    "bart_score = load(\"bertscore\")  # No direct \"bartscore\", use bertscore or integrate external lib\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    rouge_result = rouge.compute(predictions=decoded_preds, references=[l[0] for l in decoded_labels])\n",
    "    chrf_result = chrf.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bertscore_result = bart_score.compute(predictions=decoded_preds, references=[l[0] for l in decoded_labels], lang=\"si\")\n",
    "\n",
    "    # Exact Match\n",
    "    em = np.mean([p == l[0] for p, l in zip(decoded_preds, decoded_labels)])\n",
    "\n",
    "    # Token Accuracy\n",
    "    total = correct = 0\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        pred_tokens = pred.split()\n",
    "        label_tokens = label[0].split()\n",
    "        total += len(label_tokens)\n",
    "        correct += sum([p == l for p, l in zip(pred_tokens, label_tokens)])\n",
    "    token_acc = correct / total if total > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"bleu\": bleu_result[\"score\"],\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"chrf\": chrf_result[\"score\"],\n",
    "        \"exact_match\": em,\n",
    "        \"token_accuracy\": token_acc,\n",
    "        \"bertscore_f1\": np.mean(bertscore_result[\"f1\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Training Setup\n",
    "# ----------------------\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mT5-results_ta_si\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,  # Reduced for mT5-small's larger memory footprint\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=25,\n",
    "    fp16=True,\n",
    "    warmup_steps=1000,\n",
    "    lr_scheduler_type=\"cosine\", \n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"adafactor\",\n",
    "    report_to=\"tensorboard\",\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Metrics (Same as before)\n",
    "# ----------------------\n",
    "# [Keep your existing compute_metrics function]\n",
    "\n",
    "# ----------------------\n",
    "# Trainer\n",
    "# ----------------------\n",
    "from transformers import MT5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[SavePerEpochCallback(tokenizer)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint=\"/kaggle/input/last-checkpoint-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "output_dir = \"./mT5-results_ta_si\"\n",
    "\n",
    "# List checkpoint folders and sort by checkpoint number\n",
    "folders = [f for f in os.listdir(output_dir) if f.startswith(\"checkpoint\")]\n",
    "folders = sorted(folders, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "\n",
    "latest_checkpoint = folders[-1]\n",
    "checkpoint_folder = os.path.join(output_dir, latest_checkpoint)\n",
    "\n",
    "# Zip the latest checkpoint folder\n",
    "shutil.make_archive(\"last_checkpoint\", 'zip', checkpoint_folder)\n",
    "\n",
    "# Provide download link\n",
    "FileLink(\"last_checkpoint.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save full model as HuggingFace + PyTorch .pt\n",
    "model_path = \"./mT5-final-model\"\n",
    "\n",
    "# Save HuggingFace format (transformers)\n",
    "trainer.save_model(model_path)  # includes config, tokenizer, model weights\n",
    "\n",
    "# Also save raw PyTorch weights (if needed separately)\n",
    "torch.save(model.state_dict(), f\"{model_path}/mt5_final_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./mT5-final-model/mt5_final_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7731250,
     "sourceId": 12268847,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7731302,
     "sourceId": 12268918,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
