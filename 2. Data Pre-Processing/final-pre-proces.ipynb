{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfeea396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Combined and shuffled file saved as 'final_combined_shuffled_sinhala_tamil.tsv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "input_files = [\n",
    "    \"UCSC Data/parallel_corpus_second_stage.tsv\",\n",
    "    \"UOM Data/uom_parallel_corpus_second_stage.tsv\"\n",
    "]\n",
    "\n",
    "output_file = \"final_combined_shuffled_sinhala_tamil.tsv\"\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# Read all input files and collect rows (skip header)\n",
    "for filename in input_files:\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                all_rows.append(row)\n",
    "\n",
    "# Shuffle all rows randomly\n",
    "random.shuffle(all_rows)\n",
    "\n",
    "# Write combined and shuffled rows to output file with header\n",
    "with open(output_file, \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    # Write header\n",
    "    writer.writerow([\"source\", \"target\"])\n",
    "    # Write shuffled rows\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(f\"Done! Combined and shuffled file saved as '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb56ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total lines checked (excluding header): 52779\n",
      "‚ö†Ô∏è Missing source (Tamil) sentences: 0\n",
      "‚ö†Ô∏è Missing target (Sinhala) sentences: 0\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "input_file = 'final_combined_shuffled_sinhala_tamil.tsv'\n",
    "\n",
    "# Counters\n",
    "missing_source = 0\n",
    "missing_target = 0\n",
    "total_lines = 0\n",
    "\n",
    "# Read file and skip header\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()[1:]  # Skip header\n",
    "\n",
    "    for line in lines:\n",
    "        total_lines += 1\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 2:\n",
    "            continue  # Skip malformed rows\n",
    "\n",
    "        source, target = parts\n",
    "        if not source.strip():\n",
    "            missing_source += 1\n",
    "        if not target.strip():\n",
    "            missing_target += 1\n",
    "\n",
    "# Summary\n",
    "print(f\"üîç Total lines checked (excluding header): {total_lines}\")\n",
    "print(f\"‚ö†Ô∏è Missing source (Tamil) sentences: {missing_source}\")\n",
    "print(f\"‚ö†Ô∏è Missing target (Sinhala) sentences: {missing_target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9fd890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total lines checked (excluding header): 52779\n",
      "üîÅ Duplicate sentence pairs: 23\n",
      "‚úÖ Unique sentence pairs: 52756\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "input_file = 'final_combined_shuffled_sinhala_tamil.tsv'\n",
    "\n",
    "# Set to store unique sentence pairs\n",
    "unique_pairs = set()\n",
    "duplicate_count = 0\n",
    "total_lines = 0\n",
    "\n",
    "# Read file and skip header\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()[1:]  # Skip header\n",
    "\n",
    "    for line in lines:\n",
    "        total_lines += 1\n",
    "        line = line.strip()\n",
    "        if line in unique_pairs:\n",
    "            duplicate_count += 1\n",
    "        else:\n",
    "            unique_pairs.add(line)\n",
    "\n",
    "# Summary\n",
    "print(f\"üìä Total lines checked (excluding header): {total_lines}\")\n",
    "print(f\"üîÅ Duplicate sentence pairs: {duplicate_count}\")\n",
    "print(f\"‚úÖ Unique sentence pairs: {len(unique_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61551380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Duplicate Sentence Pairs with Row Numbers:\n",
      "Rows [1565, 7560] ‚Üí ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æ™‡Ææ‡Æü‡Æö‡Ææ‡Æ≤‡Øà‡Æï‡Æ≥‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç, ‡Æ™‡Æ≤‡Øç‡Æï‡Æ≤‡Øà‡Æï‡Øç ‡Æï‡Æ¥‡Æï‡Æô‡Øç‡Æï‡Æ≥‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æø‡Æü‡ØÅ‡ÆÆ‡ØÅ‡Æ±‡Øà ‡Æ®‡Ææ‡Æü‡Øç‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡Æï‡Æ±‡Øç‡Æï‡Øà ‡ÆÖ‡Æ≤‡Æï‡ØÅ‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡Ææ‡Æï‡Æ™‡Øç ‡Æ™‡ØÜ‡Æ±‡Øç‡Æ±‡ØÅ‡Æï‡Øç‡Æï‡ØÜ‡Ææ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂ª‡∂¢‡∂∫‡∑ö ‡∂¥‡∑è‡∑É‡∂Ω‡∑ä ‡∑Ñ‡∑è ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑Ä‡∑í‡∂Ø‡∑ä‡∂∫‡∑è‡∂Ω ‡∂±‡∑í‡∑Ä‡∑è‡∂©‡∑î ‡∂Ø‡∑í‡∂±‡∑Ä‡∂Ω‡∂Ø‡∑ì ‡∂ë‡∂∏ ‡∂∏‡∂∞‡∑ä‡∂∫‡∑É‡∑ä‡∂Æ‡∑è‡∂± ‡∂Ö‡∂∞‡∑ä‡∂∫‡∑è‡∂¥‡∂± ‡∂í‡∂ö‡∂ö ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂Ω‡∂∂‡∑è‡∂Ø‡∑ì‡∂∏,\n",
      "Rows [4368, 7617] ‚Üí ‡Æ§‡ØÜ‡Æô‡Øç‡Æï‡ØÅ‡Æï‡Øç ‡Æï‡ÆÆ‡Æ§‡Øç‡Æ§‡ØÜ‡Ææ‡Æ¥‡Æø‡Æ≤‡Øç, ‡Æ§‡ØÜ‡Æô‡Øç‡Æï‡ØÅ ‡Æö‡Ææ‡Æ∞‡Øç ‡Æµ‡Æ≥‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÜ‡Æï‡Æø‡ÆØ‡Æµ‡Æ±‡Øç‡Æ±‡Æø‡Æ©‡Øç ‡ÆÖ‡Æ™‡Æø‡Æµ‡Æø‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡Øá‡ÆÆ‡Øç‡Æ™‡Ææ‡Æü‡Øç‡Æü‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æí‡Æ¥‡ØÅ‡Æô‡Øç‡Æï‡ÆÆ‡Øà‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂¥‡∑ú‡∂Ω‡∑ä ‡∂ö‡∂ª‡∑ä‡∂∏‡∑è‡∂±‡∑ä‡∂≠‡∂∫‡∑ô‡∑Ñ‡∑í ‡∑É‡∑Ñ ‡∂¥‡∑ú‡∂Ω‡∑ä ‡∑É‡∂∏‡∑ä‡∂¥‡∂≠‡∑ä‡∑Ä‡∂Ω ‡∑É‡∂Ç‡∑Ä‡∂ª‡∑ä‡∂∞‡∂±‡∂∫ ‡∑Ñ‡∑è ‡∂¥‡∑ä‡∂ª‡∑Ä‡∂ª‡∑ä‡∂∞‡∂±‡∂∫ ‡∑Ä‡∑í‡∂∞‡∑í‡∂∏‡∂≠‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [12315, 18631] ‚Üí ‡Æá‡Æ≤‡Æû‡Øç‡Æö‡ÆÆ‡Øç ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡Æä‡Æ¥‡Æ≤‡Øç ‡Æ™‡Æ±‡Øç‡Æ±‡Æø‡ÆØ ‡Æö‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç‡Æï‡Æ≥‡Øà ‡Æ™‡ØÅ‡Æ≤‡Æ©‡Ææ‡ÆØ‡Øç‡Æµ‡ØÅ ‡Æö‡ØÜ‡ÆØ‡Øç‡Æµ‡Æ§‡Æ±‡Øç‡Æï‡Ææ‡Æ© ‡ÆÜ‡Æ£‡Øà‡Æï‡Øç‡Æï‡ØÅ‡Æ¥‡ØÅ‡Æö‡Øç ‡Æö‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Æø‡Æ©‡Øç ‡Æï‡ØÄ‡Æ¥‡Øç ‡Æ§‡ØÄ‡Æ∞‡Øç‡ÆÆ‡Ææ‡Æ©‡ÆÆ‡Øç,\t‡∂Ö‡∂Ω‡∑ä‡∂Ω‡∑É‡∑ä ‡∑Ñ‡∑ù ‡∂Ø‡∑ñ‡∑Ç‡∂´ ‡∂†‡∑ù‡∂Ø‡∂±‡∑è ‡∑Ä‡∑í‡∂∏‡∂ª‡∑ä‡∑Å‡∂± ‡∂ö‡∑ú‡∂∏‡∑í‡∑Ç‡∂±‡∑ä ‡∑É‡∂∑‡∑è ‡∂¥‡∂±‡∂≠ ‡∂∫‡∂ß‡∂≠‡∑ö ‡∂≠‡∑ì‡∂ª‡∂´‡∂∫,\n",
      "Rows [11696, 21024] ‚Üí ‡Æ®‡ØÜ‡Æ±‡Øç‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç‡Æö‡Øç ‡Æö‡ØÜ‡ÆØ‡Øç‡Æï‡Øà ‡ÆÆ‡Øá‡Æ±‡Øç‡Æï‡ØÜ‡Ææ‡Æ≥‡Øç‡Æ≥‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡Ææ‡Æ§‡ØÅ‡Æ≥‡Øç‡Æ≥ ‡Æµ‡ÆØ‡Æ±‡Øç‡Æï‡Ææ‡Æ£‡Æø‡Æï‡Æ≥‡Øà ‡Æ™‡ÆØ‡Æ©‡ØÅ‡Æ≥‡Øç‡Æ≥ ‡Æ®‡Æü‡Æµ‡Æü‡Æø‡Æï‡Øç‡Æï‡Øà‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∑Ä‡∑ì ‡∑Ä‡∂ú‡∑è ‡∂ö‡∑Ö ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∂ö‡∑î‡∂π‡∑î‡∂ª‡∑î ‡∂â‡∂©‡∂∏‡∑ä ‡∂µ‡∂Ω‡∂Ø‡∑è‡∂∫‡∑í ‡∂ö‡∂ß‡∂∫‡∑î‡∂≠‡∑î ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∫‡∑ú‡∂Ø‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏,\n",
      "Rows [18068, 22454] ‚Üí ‡ÆÆ‡Ææ‡Æï‡Ææ‡Æ£ ‡Æö‡Æ™‡Øà ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÇ‡Æ∞‡Ææ‡Æü‡Øç‡Æö‡Æø ‡Æ®‡Æø‡Æ±‡ØÅ‡Æµ‡Æ©‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ™‡Æø‡Æ∞‡Æ§‡Æø‡Æ®‡Æø‡Æ§‡Æø‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ™‡Æ§‡Æµ‡Æø‡Æï‡Øç ‡Æï‡Ææ‡Æ≤‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç ‡Æ™‡Æø‡Æ©‡Øç‡Æ©‡Æ∞‡ØÅ‡ÆÆ‡Øç, ‡Æö‡ÆÆ‡Ææ‡Æ§‡Ææ‡Æ© ‡Æ®‡ØÄ‡Æ§‡Æµ‡Ææ‡Æ©‡Øç ‡Æ™‡Æ§‡Æµ‡Æø‡ÆØ‡Æø‡Æ©‡Øà ‡Æµ‡Æ¥‡Æô‡Øç‡Æï‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∂¥‡∑Ö‡∑è‡∂≠‡∑ä ‡∑É‡∂∑‡∑è ‡∑É‡∑Ñ ‡∂¥‡∑Ö‡∑è‡∂≠‡∑ä ‡∂¥‡∑è‡∂Ω‡∂± ‡∂Ü‡∂∫‡∂≠‡∂±‡∑Ä‡∂Ω ‡∂∏‡∑Ñ‡∂¢‡∂± ‡∂±‡∑í‡∂∫‡∑ù‡∂¢‡∑í‡∂≠‡∂∫‡∑í‡∂±‡∂ú‡∑ö ‡∂±‡∑í‡∂Ω ‡∂ö‡∑è‡∂Ω‡∂∫‡∂ß ‡∂¥‡∑É‡∑î‡∂Ø ‡∑É‡∑è‡∂∏‡∑Ä‡∑í‡∂±‡∑í‡∑É‡∑î‡∂ª‡∑î ‡∂¥‡∂Ø‡∑Ä‡∑í‡∂∫ ‡∂Ω‡∂∂‡∑è‡∂Ø‡∑ì‡∂∏,\n",
      "Rows [8750, 22771] ‚Üí ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø‡Æü‡ÆÆ‡Ææ‡Æï‡Æø‡Æ©‡Øç‡Æ± ‡Æï‡Æø‡Æ∞‡Ææ‡ÆÆ ‡Æâ‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Øá‡Ææ‡Æï‡Æ§‡Øç‡Æ§‡Æ∞‡Øç ‡Æ™‡Æ§‡Æµ‡Æø‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡Æ™‡Æ§‡Æø‡Æ±‡Øç ‡Æï‡Æü‡ÆÆ‡Øà ‡Æ™‡ØÅ‡Æ∞‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æ®‡Æø‡ÆØ‡ÆÆ‡Æ©‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡Ææ‡Æï ‡Æµ‡Æø‡Æ©‡Øà‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Æ©‡Øç‡ÆÆ‡Æø‡Æï‡Øç‡Æï ‡Æµ‡Øá‡Æ≤‡Øà‡Æ§‡Øç‡Æ§‡Æø‡Æü‡Øç‡Æü‡ÆÆ‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Øà‡Æ§‡Øç ‡Æ§‡ÆØ‡Æ∞‡Æ∞‡Æø‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂¥‡∑î‡∂ª‡∂¥‡∑ä‡∂¥‡∑è‡∂©‡∑î ‡∑Ä‡∂± ‡∂ú‡∑ä‡∂ª‡∑è‡∂∏ ‡∂±‡∑í‡∂Ω‡∂∞‡∑è‡∂ª‡∑ì ‡∂≠‡∂±‡∂≠‡∑î‡∂ª‡∑î ‡∑Ä‡∂Ω ‡∑Ä‡∑ê‡∂© ‡∂∂‡∑ê‡∂Ω‡∑ì‡∂∏‡∑ö ‡∂¥‡∂≠‡∑ä‡∑Ä‡∑ì‡∂∏‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂ö‡∑ä‡∑Ç‡∂∏ ‡∑Ä‡∑ê‡∂© ‡∂¥‡∑í‡∑Ö‡∑í‡∑Ä‡∑ô‡∑Ö‡∂ö‡∑ä ‡∑É‡∂ö‡∑É‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [6934, 23007] ‚Üí ‡Æâ‡ÆØ‡Æ∞‡Øç ‡Æ™‡Æø‡Æ∞‡ÆÆ‡ØÅ‡Æï‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ™‡Ææ‡Æ§‡ØÅ‡Æï‡Ææ‡Æµ‡Æ≤‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡ÆÖ‡Æ©‡Øà‡Æµ‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç  ‡Æ™‡Æø‡Æ∞‡ÆØ‡Ææ‡Æ£‡Æö‡Øç ‡Æö‡ØÜ‡Æ≤‡Æµ‡ØÅ‡Æï‡Øç ‡Æï‡ØÜ‡Ææ‡Æü‡ØÅ‡Æ™‡Øç‡Æ™‡Æ©‡Æµ‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Øà ‡Æµ‡Æ¥‡Æô‡Øç‡Æï‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∑É‡∑í‡∂∫‡∂Ω‡∑î‡∂∏ ‡∂¥‡∑ä‡∂ª‡∂∑‡∑ñ ‡∂Ü‡∂ª‡∂ö‡∑ä‡∑Ç‡∂ö‡∂∫‡∑í‡∂±‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂ú‡∂∏‡∂±‡∑ä ‡∑Ä‡∑í‡∂∫‡∂Ø‡∂∏‡∑ä ‡∂Ø‡∑ì‡∂∏‡∂±‡∑è‡∑Ä‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ì‡∂∏,\n",
      "Rows [1555, 23580] ‚Üí ‡Æµ‡ØÜ‡Æ≥‡Æø‡Æ®‡Ææ‡Æü‡Øç‡Æü‡ØÅ ‡Æµ‡Øá‡Æ≤‡Øà‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡Æà‡Æü‡ØÅ‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Øá‡Ææ‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æì‡ÆØ‡Øç‡Æµ‡ØÇ‡Æ§‡Æø‡ÆØ ‡ÆÆ‡ØÅ‡Æ±‡Øà‡ÆØ‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Øà ‡ÆÖ‡Æ±‡Æø‡ÆÆ‡ØÅ‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∑Ä‡∑í‡∂Ø‡∑ö‡∑Å ‡∂ª‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∑Ä‡∂Ω ‡∂±‡∑í‡∂∫‡∑î‡∂≠‡∑î ‡∂Ö‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∑Ä‡∑í‡∑Å‡∑ä‡∂ª‡∑è‡∂∏ ‡∑Ä‡∑ê‡∂ß‡∑î‡∂¥‡∑ä ‡∂ö‡∑ä‡∂ª‡∂∏‡∂∫‡∂ö‡∑ä ‡∂Ω‡∂∂‡∑è‡∂Ø‡∑ì‡∂∏,\n",
      "Rows [15797, 26768] ‚Üí ‡Æï‡Æü‡Øç‡Æü‡Ææ‡Æï‡Øç‡Æï‡Ææ‡Æ≤‡Æø‡ÆØ‡Ææ‡Æï ‡Æ§‡Æø‡Æ∞‡Æø‡Æï‡Æø‡Æ©‡Øç‡Æ± ‡Æ®‡Ææ‡ÆØ‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÆ‡ØÇ‡Æ≤‡ÆÆ‡Øç ‡ÆÆ‡Æ©‡Æø‡Æ§ ‡Æâ‡ÆØ‡Æø‡Æ∞‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æè‡Æ±‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ©‡Øç‡Æ± ‡Æö‡Øá‡Æ§‡Æ§‡Øç‡Æ§‡Øà ‡Æ§‡Æü‡ØÅ‡Æ™‡Øç‡Æ™‡Æ§‡Æ±‡Øç‡Æï‡Ææ‡Æï ‡ÆÆ‡ØÅ‡Æ±‡Øà‡ÆØ‡Æø‡ÆØ‡Æ≤‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Øà‡Æ§‡Øç ‡Æ§‡ÆØ‡Æ∞‡Æ∞‡Æø‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂Ö‡∂∫‡∑è‡∂Ω‡∑ö ‡∂∫‡∂± ‡∑É‡∑î‡∂±‡∂õ‡∂∫‡∑í‡∂±‡∑ä‡∂ú‡∑ô‡∂±‡∑ä ‡∂∏‡∑í‡∂±‡∑í‡∑É‡∑ä ‡∂¢‡∑ì‡∑Ä‡∑í‡∂≠‡∑Ä‡∂Ω‡∂ß ‡∑É‡∑í‡∂Ø‡∑î‡∑Ä‡∂± ‡∑Ñ‡∑è‡∂±‡∑í‡∂∫ ‡∑Ä‡∑Ö‡∂ö‡∑ä‡∑Ä‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂ö‡∑ä‡∂ª‡∂∏‡∑Ä‡∑ö‡∂Ø‡∂∫‡∂ö‡∑ä ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏,\n",
      "Rows [17488, 27763] ‚Üí ‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÅ‡Æ∞‡Ææ‡Æü‡Øç‡Æö‡Æø ‡Æ®‡Æø‡Æ±‡ØÅ‡Æµ‡Æ©‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÖ‡Æ©‡Øà‡Æ§‡Øç‡Æ§‡ØÅ ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡Æø‡Æ∞‡Æ§‡Æø‡Æ®‡Æø‡Æ§‡Æø‡Æï‡Æ≥‡Æø‡Æ©‡Æ§‡ØÅ‡ÆÆ‡Øç ‡Æï‡ØÜ‡Ææ‡Æü‡ØÅ‡Æ™‡Øç‡Æ™‡Æ©‡Æµ‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æö‡Æø‡Æ±‡Æ™‡Øç‡Æ™‡ØÅ‡Æ∞‡Æø‡ÆÆ‡Øà‡Æï‡Æ≥‡Øà ‡ÆÆ‡ØÄ‡Æ≥‡Ææ‡ÆØ‡Øç‡Æµ‡ØÅ ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂¥‡∑Ö‡∑è‡∂≠‡∑ä ‡∂¥‡∑è‡∂Ω‡∂± ‡∂Ü‡∂∫‡∂≠‡∂± ‡∑Ä‡∂Ω ‡∑É‡∑í‡∂∫‡∂Ω‡∑î‡∂∏ ‡∂∏‡∑Ñ‡∂¢‡∂± ‡∂±‡∑í‡∂∫‡∑ù‡∂¢‡∑í‡∂≠‡∂∫‡∑í‡∂±‡∑ä‡∂ú‡∑ö ‡∂Ø‡∑ì‡∂∏‡∂±‡∑è ‡∑Ñ‡∑è ‡∑Ä‡∂ª‡∂¥‡∑ä‡∂ª‡∑É‡∑è‡∂Ø ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥ ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∑É‡∂Ω‡∂ö‡∑è ‡∂∂‡∑ê‡∂Ω‡∑ì‡∂∏,\n",
      "Rows [26459, 28270] ‚Üí ‡Æä‡Æ¥‡Æø‡ÆØ‡Æ∞‡Øç ‡Æö‡Øá‡ÆÆ‡Æ≤‡Ææ‡Æ™ ‡Æ®‡Æø‡Æ§‡Æø‡ÆØ‡ÆÆ‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æä‡Æ¥‡Æø‡ÆØ‡Æ∞‡Øç ‡Æ®‡ÆÆ‡Øç‡Æ™‡Æø‡Æï‡Øç‡Æï‡Øà‡Æ™‡Øç ‡Æ™‡ØÜ‡Ææ‡Æ±‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ ‡Æ®‡Æø‡Æ§‡Æø‡ÆØ‡ÆÆ‡Øç ‡ÆÜ‡Æï‡Æø‡ÆØ ‡Æ®‡Æø‡Æ§‡Æø‡ÆØ‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ ‡Æ™‡Æ£‡ÆÆ‡Øç ‡Æâ‡Æü‡Æ©‡Æü‡Æø‡ÆØ‡Ææ‡Æï ‡Æö‡ØÜ‡Æ≤‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∑É‡∑ö‡∑Ä‡∂ö ‡∂Ö‡∂ª‡∑ä‡∂Æ‡∑É‡∑è‡∂∞‡∂ö ‡∂Ö‡∂ª‡∂∏‡∑î‡∂Ø‡∂Ω‡∑í‡∂±‡∑ä ‡∑É‡∑Ñ ‡∑É‡∑ö‡∑Ä‡∂ö ‡∂∑‡∑è‡∂ª‡∂ö‡∑è‡∂ª ‡∂Ö‡∂ª‡∂∏‡∑î‡∂Ø‡∂Ω‡∑í‡∂±‡∑ä ‡∂ö‡∂©‡∑í‡∂±‡∂∏‡∑í‡∂±‡∑ä ‡∂∏‡∑î‡∂Ø‡∂Ω‡∑ä ‡∂ú‡∑ô‡∑Ä‡∑ì‡∂∏,\n",
      "Rows [25270, 28345] ‚Üí ‡Æ§‡Øá‡Æ∞‡Øç‡Æ§‡Æ≤‡Øç ‡Æ®‡Æü‡Øà‡ÆÆ‡ØÅ‡Æ±‡Øà‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ§‡Øá‡Æ∞‡Øç‡Æ§‡Æ≤‡Øç‡Æï‡Æ≥‡Øà ‡Æ®‡Æü‡Ææ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç ‡Æ™‡Æ±‡Øç‡Æ±‡Æø‡ÆØ ‡Æ™‡Ææ‡Æ∞‡Ææ‡Æ≥‡ØÅ‡ÆÆ‡Æ©‡Øç‡Æ±‡Æ§‡Øç ‡Æ§‡ØÜ‡Æ∞‡Æø ‡Æï‡ØÅ‡Æ¥‡ØÅ‡Æµ‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Øà ‡Æ®‡Æø‡ÆØ‡ÆÆ‡Æø‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂∏‡∑ê‡∂≠‡∑í‡∑Ä‡∂ª‡∂´ ‡∂ö‡∑ä‡∂ª‡∑í‡∂∫‡∑è‡∑Ä‡∂Ω‡∑í‡∂∫ ‡∑É‡∑Ñ ‡∂∏‡∑ê‡∂≠‡∑í‡∑Ä‡∂ª‡∂´ ‡∂¥‡∑ê‡∑Ä‡∑ê‡∂≠‡∑ä‡∑Ä‡∑ì‡∂∏ ‡∂¥‡∑í‡∑Ö‡∑í‡∂∂‡∂≥‡∑Ä ‡∂¥‡∑è‡∂ª‡∑ä‡∂Ω‡∑í‡∂∏‡∑ö‡∂±‡∑ä‡∂≠‡∑î ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç ‡∂ö‡∑è‡∂ª‡∂ö ‡∑É‡∂∑‡∑è‡∑Ä‡∂ö‡∑ä ‡∂¥‡∂≠‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [3348, 29438] ‚Üí ‡Æ™‡Æ≤‡Øç‡Æï‡Æ≤‡Øà‡Æï‡Øç‡Æï‡Æ¥‡Æï‡Æô‡Øç‡Æï‡Æ≥‡Ææ‡Æ≤‡Øç ‡Æ®‡Æü‡Ææ‡Æ§‡Øç‡Æ§‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ©‡Øç‡Æ± ‡Æï‡Æ±‡Øç‡Æï‡Øà ‡Æ®‡ØÜ‡Æ±‡Æø‡Æï‡Æ≥‡Øà ‡Æ§‡ØÜ‡Ææ‡Æ¥‡Æø‡Æ≤‡Øç‡ÆÆ‡Øà‡ÆØ‡Æï‡Øç ‡Æï‡Æ±‡Øç‡Æï‡Øà‡Æ®‡ØÜ‡Æ±‡Æø‡Æï‡Æ≥‡Ææ‡Æï ‡ÆÜ‡Æï‡Øç‡Æï‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑Ä‡∑í‡∂Ø‡∑ä‡∂∫‡∑è‡∂Ω ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∂¥‡∑Ä‡∂≠‡∑ä‡∑Ä‡∑è‡∂ú‡∑ô‡∂± ‡∂∫‡∂± ‡∂¥‡∑è‡∂®‡∂∏‡∑è‡∂Ω‡∑è‡∑Ä‡∂±‡∑ä ‡∂ª‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∂∑‡∑í‡∂∏‡∑î‡∂õ ‡∂¥‡∑è‡∂®‡∂∏‡∑è‡∂Ω‡∑è‡∑Ä‡∂±‡∑ä ‡∂∂‡∑Ä‡∂ß ‡∂¥‡∂≠‡∑ä‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [24631, 33443] ‚Üí ‡Æö‡ØÅ‡Æï‡Ææ‡Æ§‡Ææ‡Æ∞‡ÆÆ‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ∑‡Ææ‡Æï‡Øç‡Æï‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡Æø ‡Æ§‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡Æ§‡Øç‡Æ§‡Æø‡Æ©‡Øç ‡ÆÖ‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Ææ‡ÆØ‡ÆÆ‡Øç 5 ‡Æö‡ØÅ‡Æï‡Ææ‡Æ§‡Ææ‡Æ∞‡ÆÆ‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ∑‡Ææ‡Æï‡Øç‡Æï‡ØÅ‡Æü‡Æ©‡Øç ‡Æ§‡Øä‡Æü‡Æ∞‡Øç‡Æ™‡ØÅ‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ .\t‡∑É‡∑û‡∂õ‡∑ä‡∂∫ ‡∑Ñ‡∑è ‡∂¥‡∑ù‡∑Ç‡∂´ ‡∂∏‡∑è‡∂ª‡∑ä‡∂ú‡∑ù‡∂¥‡∂Ø‡∑ö‡∑Å‡∂±‡∂∫‡∑ö 5‡∑Ä‡∂± ‡∂¥‡∂ª‡∑í‡∂†‡∑ä‡∂°‡∑ö‡∂Ø‡∂∫‡∑ö ‡∑É‡∑û‡∂õ‡∑ä‡∂∫ ‡∑É‡∑Ñ ‡∂¥‡∑ù‡∑Ç‡∂´‡∂∫ ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞‡∂∫‡∑ô‡∂±‡∑ä ‡∂Ø‡∂ö‡∑ä‡∑Ä‡∑è ‡∂á‡∂≠\n",
      "Rows [25937, 37247] ‚Üí ‡Æï‡Ææ‡Æ≤‡Æø ‡Æï‡Øá‡Ææ‡Æü‡Øç‡Æü‡Øà ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ§‡Æ©‡Øà ‡ÆÖ‡Æ£‡Øç‡Æü‡Æø‡ÆØ‡ØÅ‡Æ≥‡Øç‡Æ≥ ‡Æµ‡Æ∞‡Æ≤‡Ææ‡Æ±‡Øç‡Æ±‡ØÅ ‡Æ∞‡ØÄ‡Æ§‡Æø‡ÆØ‡Ææ‡Æ© ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ§‡ØÜ‡Ææ‡Æ≤‡Øç‡Æ™‡ØÜ‡Ææ‡Æ∞‡ØÅ‡Æ≥‡Øç ‡ÆÆ‡Æ∞‡Æ™‡ØÅ‡Æ∞‡Æø‡ÆÆ‡Øà‡Æï‡Æ≥‡Øà‡Æ™‡Øç ‡Æ™‡Ææ‡Æ§‡ØÅ‡Æï‡Ææ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç, ‡ÆÆ‡Øá‡ÆÆ‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æâ‡Æ∞‡Æø‡ÆØ ‡Æ™‡ÆØ‡Æ©‡Øà‡Æ™‡Øç ‡Æ™‡ØÜ‡Æ±‡ØÅ‡Æµ‡Æ§‡Æ±‡Øç‡Æï‡ØÅ ‡Æ®‡Æü‡Æµ‡Æü‡Æø‡Æï‡Øç‡Æï‡Øà ‡Æé‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂ú‡∑è‡∂Ω‡∑î ‡∂ö‡∑ú‡∂ß‡∑î‡∑Ä ‡∑Ñ‡∑è ‡∂í ‡∂Ü‡∑Å‡∑ä‡∂ª‡∑í‡∂≠ ‡∂ì‡∂≠‡∑í‡∑Ñ‡∑è‡∑É‡∑í‡∂ö ‡∑Ñ‡∑è ‡∂¥‡∑î‡∂ª‡∑è ‡∑Ä‡∑í‡∂Ø‡∑ä‡∂∫‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂ã‡∂ª‡∑î‡∂∏‡∂∫‡∂±‡∑ä ‡∂Ü‡∂ª‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏, ‡∂¥‡∑ä‡∂ª‡∑Ä‡∂ª‡∑ä‡∂∞‡∂±‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑Ñ‡∑è ‡∂±‡∑í‡∑É‡∑í ‡∂¥‡∑ä‡∂ª‡∂∫‡∑ù‡∂¢‡∂± ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂ö‡∂ß‡∂∫‡∑î‡∂≠‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [36156, 37499] ‚Üí ‡Æ™‡Øá‡Æ∞‡Æø‡Æö‡Øç‡Æö‡ÆÆ‡Øç ‡Æ™‡Æ¥‡Æö‡Øç ‡Æö‡ØÜ‡ÆØ‡Øç‡Æï‡Øà‡ÆØ‡Øà ‡ÆÖ‡Æ±‡Æø‡ÆÆ‡ØÅ‡Æï‡Æ™‡Øç ‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡Æ±‡Øç‡Æï‡ØÅ‡Æ∞‡Æø‡ÆØ ‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡Æ™‡Æ±‡Øç‡Æ±‡Æø ‡Æµ‡Æø‡Æ∞‡Æø‡Æµ‡Ææ‡Æ© ‡ÆÜ‡ÆØ‡Øç‡Æµ‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Øá‡Æ±‡Øç‡Æï‡ØÜ‡Ææ‡Æ≥‡Øç‡Æ≥‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∂ª‡∂ß ‡∂â‡∂≥‡∑í ‡∑Ä‡∂ú‡∑è‡∑Ä ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∑è‡∂Ø‡∑ì‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂ö‡∑í‡∂∫‡∑è‡∑Ä ‡∑Ä‡∑í‡∂∏‡∑É‡∑è ‡∂∂‡∑ê‡∂Ω‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∑î‡∑Ö‡∑î‡∂Ω‡∑ä ‡∂Ö‡∂∞‡∑ä‡∂∫‡∂∫‡∂±‡∂∫‡∂ö‡∑ä ‡∑É‡∑í‡∂Ø‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [25355, 38063] ‚Üí ‡Æï‡Øá‡Ææ‡Æ§‡ØÅ‡ÆÆ‡Øà ‡ÆÆ‡Ææ‡Æµ‡Æø‡Æ±‡Øç‡Æï‡ØÅ‡Æ™‡Øç ‡Æ™‡Æ§‡Æø‡Æ≤‡Ææ‡Æï ‡ÆÖ‡Æ∞‡Æø‡Æö‡Æø ‡ÆÆ‡Ææ‡Æµ‡Øà ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤‡Øç ‡Æ™‡Æø‡Æ∞‡Æ™‡Æ≤‡Øç‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡Æ§‡Æ±‡Øç‡Æï‡Ææ‡Æï ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æ§‡ØÜ‡Ææ‡Æ¥‡Æø‡Æ≤‡Øç ‡Æ®‡ØÅ‡Æü‡Øç‡Æ™‡Æ§‡Øç‡Æ§‡Øà ‡ÆÖ‡Æ±‡Æø‡ÆÆ‡ØÅ‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∂≠‡∑í‡∂ª‡∑í‡∂ü‡∑î ‡∂¥‡∑í‡∂ß‡∑í ‡∑Ä‡∑ô‡∂±‡∑î‡∑Ä‡∂ß ‡∑É‡∑Ñ‡∂Ω‡∑ä ‡∂¥‡∑í‡∂ß‡∑í ‡∂¢‡∂±‡∂≠‡∑è‡∑Ä ‡∂Ö‡∂≠‡∂ª ‡∂¢‡∂±‡∂¥‡∑ä‡∂ª‡∑í‡∂∫ ‡∂ö‡∂ª‡∑Ä‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂±‡∑Ä ‡∂≠‡∑è‡∂ö‡∑ä‡∑Ç‡∂´‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∑è ‡∂Ø‡∑ì‡∂∏,\n",
      "Rows [12922, 40364] ‚Üí ‡Æï‡ØÇ‡Æü‡Øç‡Æü‡ØÅ‡Æ±‡Æµ‡ØÅ, ‡Æâ‡Æ≥‡Øç‡Æ®‡Ææ‡Æü‡Øç‡Æü‡ØÅ ‡Æµ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Æï ‡ÆÖ‡ÆÆ‡Øà‡Æö‡Øç‡Æ∞‡Øà‡Æï‡Øç ‡Æï‡Øá‡Æü‡Øç‡Æ™‡Æ§‡Æ±‡Øç‡Æï‡ØÅ,\t‡∑É‡∂∏‡∑ñ‡∂¥‡∂ö‡∑è‡∂ª ‡∑Ñ‡∑è ‡∂Ö‡∂∑‡∑ä‡∂∫‡∂±‡∑ä‡∂≠‡∂ª ‡∑Ä‡∑ô‡∑Ö‡∂≥ ‡∂Ö‡∂∏‡∑è‡∂≠‡∑ä‡∂∫‡∂≠‡∑î‡∂∏‡∑è‡∂ú‡∑ô‡∂±‡∑ä ‡∂á‡∑É‡∑ì‡∂∏‡∂ß,\n",
      "Rows [16105, 42791] ‚Üí ‡Æú‡Æ©‡Ææ‡Æ§‡Æø‡Æ™‡Æ§‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡ØÇ‡Æµ‡Æ∞‡Øà ‡Æ™‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ∞‡ØÅ‡ÆÆ‡Øç ‡Æ®‡ÆÆ‡Øç‡Æ™‡Æø‡Æï‡Øç‡Æï‡Øà ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ  ‡Æú‡Æ©‡Ææ‡Æ§‡Æø‡Æ™‡Æ§‡Æø ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Ææ‡Æ≥‡Æ∞‡Øç ‡ÆÖ‡Æ©‡ØÅ‡Æ∞‡Æµ‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æö‡Øä‡Æ©‡Øç‡Æ©‡Ææ‡Æ∞‡Øç .\t ‡∂¢‡∂±‡∑è‡∂∞‡∑í‡∂¥‡∂≠‡∑í‡∂≠‡∑î‡∂∏‡∑è‡∂ß ‡∂î‡∂∂‡∂≠‡∑î‡∂∏‡∂±‡∑ä‡∂Ω‡∑è ‡∂≠‡∑î‡∂±‡∑ä‡∂Ø‡∑ô‡∂±‡∑è ‡∂ú‡∑ê‡∂± ‡∂Ω‡∑ú‡∂ö‡∑î ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑è‡∑É‡∂∫‡∂ö‡∑ä ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑Ä‡∑è  ‡∂¢‡∂±‡∑è‡∂∞‡∑í‡∂¥‡∂≠‡∑í ‡∂Ω‡∑ö‡∂ö‡∂∏‡∑ä‡∑Ä‡∂ª‡∂∫‡∑è ‡∂Ö‡∂±‡∑î‡∂ª‡∂ß ‡∂ö‡∑ì‡∑Ä‡∑ö‡∂∫ .\n",
      "Rows [11279, 43329] ‚Üí ‡Æµ‡ØÜ‡Æ≥‡Æø‡Æ®‡Ææ‡Æü‡Øç‡Æü‡Æø‡Æ≤‡Øç ‡Æµ‡Øá‡Æ≤‡Øà ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ™‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ™‡Æø‡Æ∞‡Æö‡Øç‡Æö‡Æø‡Æ©‡Øà‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ§‡Øç ‡Æ§‡ØÄ‡Æ∞‡Øç‡Æµ‡ØÅ ‡Æï‡Ææ‡Æ£‡ØÅ‡Æ§‡Æ≤‡Øç ‡Æ§‡ØÜ‡Ææ‡Æü‡Æ∞‡Øç‡Æ™‡Æø‡Æ≤‡Øç ‡Æö‡Æü‡Øç‡Æü ‡ÆÖ‡Æ§‡Æø‡Æï‡Ææ‡Æ∞‡Æô‡Øç‡Æï‡Æ≥‡Øà‡Æï‡Øç ‡Æï‡ØÜ‡Ææ‡Æ£‡Øç‡Æü‡Æ§‡Øá‡Ææ‡Æ∞‡Øç ‡ÆÖ‡Æ≤‡Æï‡Øà ‡Æè‡Æ±‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∑Ä‡∑í‡∂Ø‡∑ö‡∑Å ‡∂ª‡∑ê‡∂ö‡∑í‡∂∫‡∑è ‡∂±‡∑í‡∂∫‡∑î‡∂ö‡∑ä‡∂≠‡∑í‡∂ö‡∂∫‡∂±‡∑ä‡∂ú‡∑ö ‡∂ú‡∑ê‡∂ß‡∂Ω‡∑î ‡∂±‡∑í‡∂ª‡∑è‡∂ö‡∂ª‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂±‡∑ì‡∂≠‡∑í‡∂∏‡∂∫ ‡∂∂‡∂Ω‡∂≠‡∂Ω ‡∑É‡∑Ñ‡∑í‡∂≠ ‡∂í‡∂ö‡∂ö‡∂∫‡∂ö‡∑ä ‡∂¥‡∑í‡∑Ñ‡∑í‡∂ß‡∑î‡∑Ä‡∑ì‡∂∏,\n",
      "Rows [18164, 46026] ‚Üí ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æï‡Æ£‡Øç‡Æü‡ØÅ‡Æ™‡Æø‡Æü‡Æø‡Æ™‡Øç‡Æ™‡Ææ‡Æ≥‡Æ∞‡Øç‡Æï‡Æ≥‡Øà ‡Æâ‡Æ≤‡Æï‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡ÆÖ‡Æ±‡Æø‡ÆÆ‡ØÅ‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÅ‡Æï‡ÆÆ‡Ææ‡Æï ‡Æ§‡Øá‡Æö‡Æø‡ÆØ ‡Æ§‡Æø‡Æü‡Øç‡Æü‡ÆÆ‡ØÜ‡Ææ‡Æ©‡Øç‡Æ±‡Æø‡Æ©‡Øà ‡Æâ‡Æ∞‡ØÅ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡ØÅ‡Æ§‡Æ≤‡Øç,\t‡∂±‡∑Ä ‡∂±‡∑í‡∂¥‡∑ê‡∂∫‡∑î‡∂∏‡∑ä‡∂ö‡∂ª‡∑î‡∑Ä‡∂±‡∑ä ‡∂Ω‡∑ù‡∂ö‡∂∫‡∂ß ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∑è ‡∂Ø‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¢‡∑è‡∂≠‡∑í‡∂ö ‡∑Ä‡∑ê‡∂© ‡∂¥‡∑í‡∑Ö‡∑í‡∑Ä‡∑ô‡∑Ö‡∂ö‡∑ä ‡∑É‡∂ö‡∑É‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [39379, 50827] ‚Üí ‡ÆÖ‡Æ∞‡Æö‡Ææ‡Æô‡Øç‡Æï ‡Æµ‡Æô‡Øç‡Æï‡Æø‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æµ‡Æü‡Øç‡Æü‡Æø ‡Æö‡ØÜ‡Æ≤‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ§‡Æ≤‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æü‡Øç‡Æü‡Æø ‡ÆÖ‡Æ±‡Æµ‡Æø‡Æü‡Æ≤‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æü‡Øà‡ÆØ‡Øá ‡Æï‡Ææ‡Æ£‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ©‡Øç‡Æ± ‡Æµ‡Æø‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Ææ‡Æö‡Æ§‡Øç‡Æ§‡Øà‡Æï‡Øç ‡Æï‡ØÅ‡Æ±‡Øà‡Æ§‡Øç‡Æ§‡Æ≤‡Øç,\t‡∂ª‡∑è‡∂¢‡∑ä‡∂∫ ‡∂∂‡∑ê‡∂Ç‡∂ö‡∑î‡∑Ä‡∂Ω ‡∂¥‡∑ú‡∂Ω‡∑ì ‡∂ú‡∑ô‡∑Ä‡∑ì‡∂∏ ‡∑É‡∑Ñ ‡∂¥‡∑ú‡∂Ω‡∑ì ‡∂Ö‡∂∫‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∂Ö‡∂≠‡∂ª ‡∂¥‡∑Ä‡∂≠‡∑í‡∂± ‡∂¥‡∂ª‡∂≠‡∂ª‡∂∫ ‡∂Ö‡∂©‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏,\n",
      "Rows [32837, 52536] ‚Üí ‡Æµ‡ØÜ‡Æ≥‡Æø‡Æ®‡Ææ‡Æü‡Øç‡Æü‡ØÅ‡Æµ‡Øá‡Æ≤‡Øà‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡ØÅ ‡Æä‡Æï‡Øç‡Æï‡ØÅ‡Æµ‡Æø‡Æ™‡Øç‡Æ™‡ØÅ, ‡Æ®‡Æ≤‡Æ©‡Øá‡Ææ‡ÆÆ‡Øç‡Æ™‡ØÅ‡Æï‡Øà ‡ÆÖ‡ÆÆ‡Øà‡Æö‡Øç‡Æö‡Æ∞‡Øà‡Æï‡Øç ‡Æï‡Øá‡Æü‡Øç‡Æ™‡Æ§‡Æ±‡Øç‡Æï‡ØÅ,\t‡∑Ä‡∑í‡∂Ø‡∑ö‡∑Å ‡∂ª‡∑ê‡∂ö‡∑í‡∂∫‡∑è ‡∂¥‡∑ä‡∂ª‡∑Ä‡∂ª‡∑ä‡∂∞‡∂± ‡∑Ñ‡∑è ‡∑É‡∑î‡∂∂‡∑É‡∑è‡∂∞‡∂± ‡∂Ö‡∂∏‡∑è‡∂≠‡∑ä‡∂∫‡∂≠‡∑î‡∂∏‡∑è‡∂ú‡∑ô‡∂±‡∑ä ‡∂á‡∑É‡∑ì‡∂∏‡∂ß,\n",
      "\n",
      "‚úÖ Total duplicate sentence pairs: 23\n",
      "üìÅ Duplicates saved to: final_duplicates.tsv\n",
      "üìÅ without_duplicates data saved to: final_parallel_corpus_without_duplicates.tsv\n"
     ]
    }
   ],
   "source": [
    "# Input and output files\n",
    "input_file = 'final_combined_shuffled_sinhala_tamil.tsv'\n",
    "duplicates_file = 'final_duplicates.tsv'\n",
    "without_duplicates_file = 'final_parallel_corpus_without_duplicates.tsv'\n",
    "\n",
    "# Dictionaries to track data\n",
    "line_to_rows = {}     # line -> list of row numbers\n",
    "duplicates = []\n",
    "without_duplicates = []\n",
    "seen_once = set()\n",
    "\n",
    "# Read file\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "header = lines[0].strip()\n",
    "data_lines = lines[1:]\n",
    "\n",
    "# Track line numbers (starting from 2 because line 1 is header)\n",
    "for idx, line in enumerate(data_lines, start=2):\n",
    "    line = line.strip()\n",
    "    if line not in line_to_rows:\n",
    "        line_to_rows[line] = [idx]\n",
    "        without_duplicates.append(line)\n",
    "    else:\n",
    "        line_to_rows[line].append(idx)\n",
    "        if line not in seen_once:\n",
    "            duplicates.append(line)\n",
    "            seen_once.add(line)\n",
    "\n",
    "# ‚úÖ Print duplicates with row numbers\n",
    "print(\"üîÅ Duplicate Sentence Pairs with Row Numbers:\")\n",
    "for dup in duplicates:\n",
    "    rows = line_to_rows[dup]\n",
    "    print(f\"Rows {rows} ‚Üí {dup}\")\n",
    "\n",
    "# üíæ Save duplicates for reference\n",
    "with open(duplicates_file, 'w', encoding='utf-8') as df:\n",
    "    df.write(\"row_numbers\\tsource\\ttarget\\n\")\n",
    "    for dup in duplicates:\n",
    "        source, target = dup.split('\\t')\n",
    "        row_numbers = ','.join(map(str, line_to_rows[dup]))\n",
    "        df.write(f\"{row_numbers}\\t{source}\\t{target}\\n\")\n",
    "\n",
    "# üíæ Save without_duplicates data (only first occurrence)\n",
    "with open(without_duplicates_file, 'w', encoding='utf-8') as cf:\n",
    "    cf.write(header + '\\n')\n",
    "    for line in without_duplicates:\n",
    "        cf.write(line + '\\n')\n",
    "\n",
    "# ‚úÖ Summary\n",
    "print(f\"\\n‚úÖ Total duplicate sentence pairs: {len(duplicates)}\")\n",
    "print(f\"üìÅ Duplicates saved to: {duplicates_file}\")\n",
    "print(f\"üìÅ without_duplicates data saved to: {without_duplicates_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1ea05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with unwanted chars in source: 7375\n",
      "Rows with unwanted chars in target: 8902\n",
      "Unwanted characters and counts saved to 'final_unwanted_chars_source.tsv' and 'final_unwanted_chars_target.tsv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# Your input file path\n",
    "input_file = 'final_parallel_corpus_without_duplicates.tsv'\n",
    "\n",
    "# Load parallel corpus\n",
    "df = pd.read_csv(input_file, delimiter='\\t', names=['source', 'target'], encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "# Regex pattern: allow Tamil \\u0B80-\\u0BFF, Sinhala \\u0D80-\\u0DFF, whitespace, and basic punctuation (.,!?) only\n",
    "pattern = r'[^\\u0B80-\\u0BFF\\u0D80-\\u0DFF\\s.,!?]'\n",
    "\n",
    "# Function to detect if text contains unwanted characters\n",
    "def has_unwanted_char(text):\n",
    "    return bool(re.search(pattern, str(text)))\n",
    "\n",
    "# Function to extract unwanted characters from text\n",
    "def extract_unwanted_chars(text):\n",
    "    return re.findall(pattern, str(text))\n",
    "\n",
    "# Find rows with unwanted characters\n",
    "source_unwanted_mask = df['source'].apply(has_unwanted_char)\n",
    "target_unwanted_mask = df['target'].apply(has_unwanted_char)\n",
    "\n",
    "print(\"Rows with unwanted chars in source:\", source_unwanted_mask.sum())\n",
    "print(\"Rows with unwanted chars in target:\", target_unwanted_mask.sum())\n",
    "\n",
    "# Extract unwanted characters from those rows\n",
    "source_unwanted_chars = df.loc[source_unwanted_mask, 'source'].apply(extract_unwanted_chars)\n",
    "target_unwanted_chars = df.loc[target_unwanted_mask, 'target'].apply(extract_unwanted_chars)\n",
    "\n",
    "# Flatten lists and count frequency\n",
    "source_counts = Counter(chain.from_iterable(source_unwanted_chars))\n",
    "target_counts = Counter(chain.from_iterable(target_unwanted_chars))\n",
    "\n",
    "# Convert to DataFrame and sort descending by count\n",
    "source_df = pd.DataFrame(source_counts.items(), columns=['character', 'count']).sort_values(by='count', ascending=False)\n",
    "target_df = pd.DataFrame(target_counts.items(), columns=['character', 'count']).sort_values(by='count', ascending=False)\n",
    "\n",
    "# Save to TSV for review\n",
    "source_df.to_csv('unwanted charactes/final_unwanted_chars_source.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "target_df.to_csv('unwanted charactes/final_unwanted_chars_target.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Unwanted characters and counts saved to 'final_unwanted_chars_source.tsv' and 'final_unwanted_chars_target.tsv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9fa983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined unwanted characters saved to 'unwanted charactes/final_unwanted_characters_combined.tsv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "input_file = 'final_parallel_corpus_without_duplicates.tsv'\n",
    "\n",
    "# Load file with skipping bad lines\n",
    "df = pd.read_csv(input_file, delimiter='\\t', names=['source', 'target'], encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "# Regex to match unwanted characters (not Tamil, Sinhala, space or basic punctuation)\n",
    "pattern = r'[^\\u0B80-\\u0BFF\\u0D80-\\u0DFF\\s.,!?]'\n",
    "\n",
    "def has_unwanted_char(text):\n",
    "    return bool(re.search(pattern, str(text)))\n",
    "\n",
    "def extract_unwanted_chars(text):\n",
    "    return re.findall(pattern, str(text))\n",
    "\n",
    "# Filter rows with unwanted characters in source and target\n",
    "source_unwanted_chars = df.loc[df['source'].apply(has_unwanted_char), 'source'].apply(extract_unwanted_chars)\n",
    "target_unwanted_chars = df.loc[df['target'].apply(has_unwanted_char), 'target'].apply(extract_unwanted_chars)\n",
    "\n",
    "# Combine all unwanted chars from both columns into one list\n",
    "all_unwanted_chars = list(chain.from_iterable(source_unwanted_chars)) + list(chain.from_iterable(target_unwanted_chars))\n",
    "\n",
    "# Count frequency of all unwanted characters combined\n",
    "combined_counts = Counter(all_unwanted_chars)\n",
    "\n",
    "# Convert to DataFrame\n",
    "combined_df = pd.DataFrame(combined_counts.items(), columns=['character', 'count']).sort_values(by='count', ascending=False)\n",
    "\n",
    "# Save to single TSV file\n",
    "combined_df.to_csv('unwanted charactes/final_unwanted_characters_combined.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Combined unwanted characters saved to 'unwanted charactes/final_unwanted_characters_combined.tsv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586b565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ''\\u200d'' from both columns and saved to 'final_parallel_corpus_second_stage.tsv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = 'final_parallel_corpus_without_duplicates.tsv'\n",
    "output_file = 'final_parallel_corpus_second_stage.tsv'\n",
    "\n",
    "# Load file and use the first row as header\n",
    "df = pd.read_csv(input_file, delimiter='\\t', encoding='utf-8', on_bad_lines='skip', header=0)\n",
    "\n",
    "# Character to remove - the ZERO WIDTH JOINER (Unicode U+200D)\n",
    "char_to_remove = '\\u200d'\n",
    "\n",
    "# Remove the character from both columns\n",
    "df['source'] = df['source'].str.replace(char_to_remove, '', regex=False)\n",
    "df['target'] = df['target'].str.replace(char_to_remove, '', regex=False)\n",
    "\n",
    "# Save cleaned dataframe with header\n",
    "df.to_csv(output_file, sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Removed '{repr(char_to_remove)}' from both columns and saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecaf6e",
   "metadata": {},
   "source": [
    "# Manuvaly Removed other Unwanted Characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
